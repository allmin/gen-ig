import pandas as pd
import numpy as np
import os
# from pattern.en import conjugate
from config import system_name, scope_name, unknown_phrase, tense_dict, reserved_keywords, recommendation_count
from utils.commonlib import unique, flatten, streval
from sklearn.cluster import KMeans
# import regex as re
# import os, sys
# scope_name = 'user02'

def perform_kmeans(K,X):
    kmeans = KMeans(n_clusters=K, random_state=123).fit(X)
    return kmeans.labels_

def save_to_system_folder(df,prefix):
    if scope_name and scope_name != '':
        df.to_excel("systems/{}/{}_{}_{}.xlsx".format(system_name,prefix,scope_name,system_name), index=False)
        df.to_pickle("systems/{}/{}_{}_{}.pickle".format(system_name,prefix,scope_name,system_name), protocol=4)
    else:
        df.to_excel("systems/{}/{}_{}.xlsx".format(system_name,prefix,system_name), index=False)
        df.to_pickle("systems/{}/{}_{}.pickle".format(system_name,prefix,system_name), protocol=4)


if __name__ == '__main__':
    sorting_criteria = 'pscore_final'
    if scope_name and scope_name != '':
        scored_library = pd.read_pickle("systems/{}/scored_insights_final_{}_{}.pickle".format(system_name,scope_name,system_name))
    else:
        scored_library = pd.read_pickle("systems/{}/scored_insights_final_{}.pickle".format(system_name,system_name))

    # elliminating insignificant insights:
    scored_library = scored_library[scored_library['pvalue'] < 0.05]

    list_of_filters = unique(flatten([list(streval(i).keys()) for i in scored_library['intermediate']]))
    list_of_filters_AB = flatten([[i+'_A', i+'_B'] if i!='measurement' else [i] for i in list_of_filters])

    insight_identifier = []
    for col in list_of_filters_AB:
        if len(insight_identifier) != 0:
            insight_identifier = insight_identifier + '|' + scored_library[col]
        else:
            insight_identifier = 'schema'+scored_library['schema_num'].astype(str)+'|'+scored_library[col]

    vocabulary = {}
    tokens = []
    for i in insight_identifier.values:
        for j in i.split('|'):
            for k in j.split('_'):
                if (k not in vocabulary) and (k!=''):

                    vocabulary[k] = len(vocabulary)
    inverse_vocabulary = {v:k for k,v in vocabulary.items()}

    feature_vector = np.zeros((len(insight_identifier),len(vocabulary)))
    for ind,i in enumerate(insight_identifier.values):
        for j in i.split('|'):
            for k in j.split('_'):
                if k in vocabulary:
                    k_ind = vocabulary[k]
                    feature_vector[ind][k_ind] += 1
    
    num_insights_needed = recommendation_count
    cluster_labels = perform_kmeans(K=num_insights_needed,X=feature_vector)
    scored_library['cluster_labels'] = cluster_labels
    scored_library['feature_vector'] = [i for i in feature_vector]
    scored_library['insight_identifier'] = insight_identifier
    save_to_system_folder(df=scored_library,prefix='scored_insights_final_with_clusters')
    

    recommended_insights = pd.DataFrame()
    for i in range(num_insights_needed):
        insight_candidates = scored_library[scored_library['cluster_labels'] == i]
        insight_candidate = insight_candidates[insight_candidates[sorting_criteria] == (insight_candidates[sorting_criteria].min())]
        if len(recommended_insights) == 0:
            recommended_insights = insight_candidate
        else:
            recommended_insights = pd.concat([recommended_insights,insight_candidate])
    
    save_to_system_folder(df=recommended_insights,prefix='recommended_insights_final')

    try:
        if system_name == 'iphil' and os.getcwd().split(os.path.sep)[-1] == 'get_insights':
            prefix = 'scored_insights_final_with_clusters'
            scored_library.to_pickle("../../actions/data/{}_{}_{}.pickle".format(prefix,scope_name,system_name), protocol=4)
    except Exception as e:
        print(e)

